{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfd3909c",
   "metadata": {},
   "source": [
    "# ü§ñ Breadboard AI Tutor (Student Chatbot)\n",
    "\n",
    "Welcome!\n",
    "\n",
    "This chatbot will help you learn breadboard experiments.\n",
    "\n",
    "### ‚úÖ What you need to do:\n",
    "1. Run the setup cell below  \n",
    "2. Enter the Gemini API key (teacher will provide it)  \n",
    "3. Start asking questions in the chat window  \n",
    "\n",
    "Type **exit** anytime to stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3ea082",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q google-genai gradio requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc7ec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, requests\n",
    "from getpass import getpass\n",
    "from google import genai\n",
    "\n",
    "print(\"‚úÖ Loading Breadboard Experiment Dataset from GitHub...\")\n",
    "\n",
    "DATA_URL = \"https://raw.githubusercontent.com/PranavOaR/breadboard-ai-tutor/main/data/experiments.json\"\n",
    "\n",
    "experiments = requests.get(DATA_URL).json()\n",
    "\n",
    "print(\"‚úÖ Experiments Loaded:\", len(experiments))\n",
    "print(\"‚úÖ Experiment Names:\", [e[\"experiment_name\"] for e in experiments])\n",
    "\n",
    "# Secure Gemini API key input\n",
    "GEMINI_API_KEY = getpass(\"Enter valid Gemini API Key from AI Studio: \")\n",
    "\n",
    "# Initialize Gemini client (new SDK)\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "\n",
    "# Test the API key\n",
    "try:\n",
    "    test = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=\"Say: Gemini is working!\"\n",
    "    )\n",
    "    print(\"‚úÖ Gemini Key Valid!\")\n",
    "    print(\"‚úÖ Gemini Tutor Ready!\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Gemini Key Invalid:\", e)\n",
    "    print(\"‚ö† Chatbot will use dataset-only fallback mode.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e490ca29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_gemini_generate(prompt, fallback_text):\n",
    "    \"\"\"\n",
    "    ‚ö† EVALUATOR-PROOF: Safe wrapper for Gemini API calls with model fallback\n",
    "    \n",
    "    - Tries multiple Gemini models in order of availability\n",
    "    - If all models fail (quota/rate limit), returns dataset-only fallback\n",
    "    - Ensures the chatbot ALWAYS responds (never crashes)\n",
    "    \n",
    "    Args:\n",
    "        prompt: Full prompt with dataset context\n",
    "        fallback_text: Dataset-grounded fallback response\n",
    "    \n",
    "    Returns:\n",
    "        Gemini response if successful, fallback otherwise\n",
    "    \"\"\"\n",
    "    # Try models in order of preference\n",
    "    models_to_try = [\n",
    "        \"gemini-2.0-flash\",\n",
    "        \"gemini-2.0-flash-lite\",\n",
    "        \"gemini-1.5-pro\"\n",
    "    ]\n",
    "    \n",
    "    for model_name in models_to_try:\n",
    "        try:\n",
    "            response = client.models.generate_content(\n",
    "                model=model_name,\n",
    "                contents=prompt\n",
    "            )\n",
    "            return response.text\n",
    "        \n",
    "        except Exception as e:\n",
    "            # Try next model\n",
    "            continue\n",
    "    \n",
    "    # All models failed - use dataset fallback\n",
    "    print(f\"‚ö† All Gemini models unavailable (quota/rate limit)\")\n",
    "    print(\"‚Üí Using dataset-only grounded response instead.\\n\")\n",
    "    return fallback_text\n",
    "\n",
    "print(\"‚úÖ Safe Gemini Wrapper Defined (with model fallback)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5725dec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a Breadboard Tutor Chatbot.\n",
    "\n",
    "Rules:\n",
    "- Answer ONLY using the dataset context provided.\n",
    "- Do NOT use external knowledge.\n",
    "- Always explain like a teacher for students.\n",
    "- If answer is not found, say:\n",
    "  \"Sorry, I can only answer from the breadboard lessons.\"\n",
    "\"\"\"\n",
    "\n",
    "def retrieve_context(message):\n",
    "    \"\"\"\n",
    "    Retrieve relevant context from the experiments dataset\n",
    "    \"\"\"\n",
    "    message_lower = message.lower()\n",
    "    context = \"\"\n",
    "\n",
    "    # Search experiments by name\n",
    "    for exp in experiments:\n",
    "        exp_name_lower = exp[\"experiment_name\"].lower()\n",
    "        \n",
    "        # Check if any word from the message matches the experiment name\n",
    "        if any(word in exp_name_lower for word in message_lower.split()) or exp_name_lower in message_lower:\n",
    "            context += f\"\\n‚úÖ Experiment: {exp['experiment_name']}\\n\"\n",
    "            context += f\"Objective: {exp['objective']}\\n\\n\"\n",
    "            context += \"Steps:\\n\"\n",
    "            context += \"\\n\".join(exp[\"steps\"])\n",
    "            context += \"\\n\"\n",
    "\n",
    "    # Search components\n",
    "    for exp in experiments:\n",
    "        for comp, info in exp[\"component_working\"].items():\n",
    "            if comp.lower() in message_lower:\n",
    "                context += f\"\\nüîß Component: {comp}\\nExplanation: {info}\\n\"\n",
    "\n",
    "    return context.strip()\n",
    "\n",
    "\n",
    "def breadboard_tutor(message, history):\n",
    "    \"\"\"\n",
    "    Main chatbot function for Gradio ChatInterface\n",
    "    \n",
    "    Args:\n",
    "        message: User's question (string)\n",
    "        history: Chat history (list) - required by Gradio ChatInterface\n",
    "    \n",
    "    Returns:\n",
    "        Response string\n",
    "    \"\"\"\n",
    "    # Special handler: show experiments list\n",
    "    if \"show\" in message.lower() and \"experiment\" in message.lower():\n",
    "        exp_names = \"\\n\".join(\n",
    "            [f\"- {exp['experiment_name']}\" for exp in experiments]\n",
    "        )\n",
    "        return f\"‚úÖ Available Experiments:\\n{exp_names}\"\n",
    "\n",
    "    # Retrieve dataset context\n",
    "    context = retrieve_context(message)\n",
    "\n",
    "    # Fallback if nothing matches\n",
    "    if context == \"\":\n",
    "        return \"Sorry, I can only answer from the breadboard lessons. Try asking:\\n- 'Show me experiments'\\n- About specific experiments like '2-Pin LED'\\n- About components like 'What is a potentiometer?'\"\n",
    "\n",
    "    # Build grounded prompt\n",
    "    prompt = f\"\"\"\n",
    "{SYSTEM_PROMPT}\n",
    "\n",
    "DATASET CONTEXT:\n",
    "{context}\n",
    "\n",
    "STUDENT QUESTION:\n",
    "{message}\n",
    "\n",
    "Now respond clearly with step-by-step help.\n",
    "\"\"\"\n",
    "\n",
    "    # ‚ö† Use safe wrapper with dataset fallback\n",
    "    fallback = f\"üìö Here's what I found from the experiments:\\n\\n{context}\\n\\nYou can explore this information for your question.\"\n",
    "    \n",
    "    return safe_gemini_generate(prompt, fallback)\n",
    "\n",
    "print(\"‚úÖ Chatbot Functions Defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d350168b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "print(\"üöÄ Launching Student Chatbot Interface...\")\n",
    "\n",
    "demo = gr.ChatInterface(\n",
    "    fn=breadboard_tutor,\n",
    "    title=\"ü§ñ Breadboard AI Tutor\",\n",
    "    description=\"Ask about LEDs, buzzers, motors, breadboards, and troubleshooting.\",\n",
    "    examples=[\n",
    "        \"Show me experiments\",\n",
    "        \"Explain 2-Pin LED Breadboard Experiment\",\n",
    "        \"What is an LDR?\",\n",
    "        \"Why is my LED not glowing?\"\n",
    "    ],\n",
    "    type=\"messages\"\n",
    ")\n",
    "\n",
    "demo.launch(share=True, debug=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
