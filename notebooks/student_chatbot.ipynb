{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfd3909c",
   "metadata": {},
   "source": [
    "# ü§ñ Breadboard AI Tutor (Student Chatbot)\n",
    "\n",
    "Welcome!\n",
    "\n",
    "This chatbot will help you learn breadboard experiments.\n",
    "\n",
    "### ‚úÖ What you need to do:\n",
    "1. Run the setup cell below  \n",
    "2. Enter the Groq API key (get free from [console.groq.com](https://console.groq.com))  \n",
    "3. Start asking questions in the chat window  \n",
    "\n",
    "Type **exit** anytime to stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3ea082",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q groq gradio requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc7ec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, requests\n",
    "from getpass import getpass\n",
    "from groq import Groq\n",
    "\n",
    "print(\"‚úÖ Loading Breadboard Experiment Dataset from GitHub...\")\n",
    "\n",
    "DATA_URL = \"https://raw.githubusercontent.com/PranavOaR/breadboard-ai-tutor/main/data/experiments.json\"\n",
    "\n",
    "experiments = requests.get(DATA_URL).json()\n",
    "\n",
    "print(\"‚úÖ Experiments Loaded:\", len(experiments))\n",
    "print(\"‚úÖ Experiment Names:\", [e[\"experiment_name\"] for e in experiments])\n",
    "\n",
    "# Secure Groq API key input\n",
    "GROQ_API_KEY = getpass(\"Enter Groq API Key (from console.groq.com): \")\n",
    "\n",
    "# Initialize Groq client\n",
    "client = Groq(api_key=GROQ_API_KEY)\n",
    "\n",
    "# Test the API key\n",
    "try:\n",
    "    test = client.chat.completions.create(\n",
    "        model=\"llama-3.1-8b-instant\",\n",
    "        messages=[{\"role\": \"user\", \"content\": \"Say: Groq is working!\"}],\n",
    "        max_tokens=50\n",
    "    )\n",
    "    print(\"‚úÖ Groq Key Valid!\")\n",
    "    print(\"‚úÖ Groq Tutor Ready!\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Groq Key Invalid:\", e)\n",
    "    print(\"‚ö† Chatbot will use dataset-only fallback mode.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e490ca29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_groq_generate(prompt, fallback_text):\n",
    "    \"\"\"\n",
    "    Safe wrapper for Groq API calls with silent fallback\n",
    "    \n",
    "    - Tries Groq API for enhanced tutor responses\n",
    "    - If API fails (quota/rate limit), silently returns dataset-only fallback\n",
    "    - Ensures the chatbot ALWAYS responds (never crashes)\n",
    "    \n",
    "    Args:\n",
    "        prompt: Full prompt with dataset context\n",
    "        fallback_text: Dataset-grounded fallback response\n",
    "    \n",
    "    Returns:\n",
    "        Groq response if successful, fallback otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"llama-3.1-8b-instant\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful breadboard tutor.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=1024\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except:\n",
    "        # Silent fallback (no prints, no warnings)\n",
    "        return fallback_text\n",
    "\n",
    "print(\"‚úÖ Safe Groq Wrapper Defined (with silent fallback)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5725dec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a Breadboard Tutor Chatbot.\n",
    "\n",
    "Rules:\n",
    "- Answer ONLY using the dataset context provided.\n",
    "- Do NOT use external knowledge.\n",
    "- Always explain like a teacher for students.\n",
    "- If answer is not found, say:\n",
    "  \"Sorry, I can only answer from the breadboard lessons.\"\n",
    "\"\"\"\n",
    "\n",
    "def retrieve_context(message):\n",
    "    \"\"\"\n",
    "    Retrieve relevant context from the experiments dataset\n",
    "    \"\"\"\n",
    "    message_lower = message.lower()\n",
    "    context = \"\"\n",
    "\n",
    "    # Search experiments by name\n",
    "    for exp in experiments:\n",
    "        exp_name_lower = exp[\"experiment_name\"].lower()\n",
    "        \n",
    "        # Check if any word from the message matches the experiment name\n",
    "        if any(word in exp_name_lower for word in message_lower.split()) or exp_name_lower in message_lower:\n",
    "            context += f\"\\n‚úÖ Experiment: {exp['experiment_name']}\\n\"\n",
    "            context += f\"Objective: {exp['objective']}\\n\\n\"\n",
    "            context += \"Steps:\\n\"\n",
    "            context += \"\\n\".join(exp[\"steps\"])\n",
    "            context += \"\\n\"\n",
    "\n",
    "    # Search components\n",
    "    for exp in experiments:\n",
    "        for comp, info in exp[\"component_working\"].items():\n",
    "            if comp.lower() in message_lower:\n",
    "                context += f\"\\nüîß Component: {comp}\\nExplanation: {info}\\n\"\n",
    "\n",
    "    return context.strip()\n",
    "\n",
    "\n",
    "def breadboard_tutor(message, history):\n",
    "    \"\"\"\n",
    "    Main chatbot function for Gradio ChatInterface\n",
    "    \n",
    "    Args:\n",
    "        message: User's question (string)\n",
    "        history: Chat history (list) - required by Gradio ChatInterface\n",
    "    \n",
    "    Returns:\n",
    "        Response string\n",
    "    \"\"\"\n",
    "    # Special handler: show experiments list\n",
    "    if \"show\" in message.lower() and \"experiment\" in message.lower():\n",
    "        exp_names = \"\\n\".join(\n",
    "            [f\"- {exp['experiment_name']}\" for exp in experiments]\n",
    "        )\n",
    "        return f\"‚úÖ Available Experiments:\\n{exp_names}\"\n",
    "\n",
    "    # Retrieve dataset context\n",
    "    context = retrieve_context(message)\n",
    "\n",
    "    # Fallback if nothing matches\n",
    "    if context == \"\":\n",
    "        return \"Sorry, I can only answer from the breadboard lessons. Try asking:\\n- 'Show me experiments'\\n- About specific experiments like '2-Pin LED'\\n- About components like 'What is a potentiometer?'\"\n",
    "\n",
    "    # Build grounded prompt\n",
    "    prompt = f\"\"\"\n",
    "{SYSTEM_PROMPT}\n",
    "\n",
    "DATASET CONTEXT:\n",
    "{context}\n",
    "\n",
    "STUDENT QUESTION:\n",
    "{message}\n",
    "\n",
    "Now respond clearly with step-by-step help.\n",
    "\"\"\"\n",
    "\n",
    "    # ‚ö† Use safe wrapper with dataset fallback\n",
    "    fallback = f\"üìö Here's what I found from the experiments:\\n\\n{context}\\n\\nYou can explore this information for your question.\"\n",
    "    \n",
    "    return safe_groq_generate(prompt, fallback)\n",
    "\n",
    "print(\"‚úÖ Chatbot Functions Defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d350168b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "print(\"üöÄ Launching Student Chatbot Interface...\")\n",
    "\n",
    "demo = gr.ChatInterface(\n",
    "    fn=breadboard_tutor,\n",
    "    title=\"ü§ñ Breadboard AI Tutor\",\n",
    "    description=\"Ask about LEDs, buzzers, motors, breadboards, and troubleshooting.\",\n",
    "    examples=[\n",
    "        \"Show me experiments\",\n",
    "        \"Explain 2-Pin LED Breadboard Experiment\",\n",
    "        \"What is an LDR?\",\n",
    "        \"Why is my LED not glowing?\"\n",
    "    ],\n",
    "    type=\"messages\"\n",
    ")\n",
    "\n",
    "demo.launch(share=True, debug=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
