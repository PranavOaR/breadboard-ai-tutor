{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfd3909c",
   "metadata": {},
   "source": [
    "# \ud83e\udd16 Breadboard AI Tutor (Student Chatbot)\n",
    "\n",
    "Welcome!\n",
    "\n",
    "This chatbot will help you learn breadboard experiments.\n",
    "\n",
    "### \u2705 What you need to do:\n",
    "1. Run the setup cell below  \n",
    "2. Enter the Gemini API key (teacher will provide it)  \n",
    "3. Start asking questions in the chat window  \n",
    "\n",
    "Type **exit** anytime to stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3ea082",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q google-genai gradio requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc7ec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, requests\n",
    "from getpass import getpass\n",
    "from google import genai\n",
    "\n",
    "print(\"\u2705 Loading Breadboard Experiment Dataset from GitHub...\")\n",
    "\n",
    "DATA_URL = \"https://raw.githubusercontent.com/PranavOaR/breadboard-ai-tutor/main/data/experiments.json\"\n",
    "\n",
    "experiments = requests.get(DATA_URL).json()\n",
    "\n",
    "print(\"\u2705 Experiments Loaded:\", len(experiments))\n",
    "print(\"\u2705 Experiment Names:\", [e[\"experiment_name\"] for e in experiments])\n",
    "\n",
    "# Secure Gemini API key input\n",
    "GEMINI_API_KEY = getpass(\"Enter valid Gemini API Key from AI Studio: \")\n",
    "\n",
    "# Initialize Gemini client (new SDK)\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "\n",
    "# Test the API key\n",
    "try:\n",
    "    test = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=\"Say: Gemini is working!\"\n",
    "    )\n",
    "    print(\"\u2705 Gemini Key Valid!\")\n",
    "    print(\"\u2705 Gemini Tutor Ready!\")\n",
    "except Exception as e:\n",
    "    print(\"\u274c Gemini Key Invalid:\", e)\n",
    "    print(\"\u26a0 Chatbot will use dataset-only fallback mode.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e490ca29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_gemini_generate(prompt, fallback_text):\n",
    "    \"\"\"Safe wrapper for Gemini API calls with silent fallback\"\"\"\n",
    "    try:\n",
    "        response = client.models.generate_content(model=\"gemini-2.0-flash\", contents=prompt)\n",
    "        return response.text\n",
    "    except:\n",
    "        return fallback_text\n",
    "\n",
    "print(\"\u2705 Safe Gemini Wrapper Defined (with silent fallback)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5725dec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a Breadboard Tutor Chatbot.\n",
    "\n",
    "Rules:\n",
    "- Answer ONLY using the dataset context provided.\n",
    "- Do NOT use external knowledge.\n",
    "- Always explain like a teacher for students.\n",
    "- If answer is not found, say:\n",
    "  \"Sorry, I can only answer from the breadboard lessons.\"\n",
    "\"\"\"\n",
    "\n",
    "def retrieve_context(message):\n",
    "    \"\"\"\n",
    "    Retrieve relevant context from the experiments dataset\n",
    "    \"\"\"\n",
    "    message_lower = message.lower()\n",
    "    context = \"\"\n",
    "\n",
    "    # Search experiments by name\n",
    "    for exp in experiments:\n",
    "        exp_name_lower = exp[\"experiment_name\"].lower()\n",
    "        \n",
    "        # Check if any word from the message matches the experiment name\n",
    "        if any(word in exp_name_lower for word in message_lower.split()) or exp_name_lower in message_lower:\n",
    "            context += f\"\\n\u2705 Experiment: {exp['experiment_name']}\\n\"\n",
    "            context += f\"Objective: {exp['objective']}\\n\\n\"\n",
    "            context += \"Steps:\\n\"\n",
    "            context += \"\\n\".join(exp[\"steps\"])\n",
    "            context += \"\\n\"\n",
    "\n",
    "    # Search components\n",
    "    for exp in experiments:\n",
    "        for comp, info in exp[\"component_working\"].items():\n",
    "            if comp.lower() in message_lower:\n",
    "                context += f\"\\n\ud83d\udd27 Component: {comp}\\nExplanation: {info}\\n\"\n",
    "\n",
    "    return context.strip()\n",
    "\n",
    "\n",
    "def breadboard_tutor(message, history):\n",
    "    \"\"\"\n",
    "    Main chatbot function for Gradio ChatInterface\n",
    "    \n",
    "    Args:\n",
    "        message: User's question (string)\n",
    "        history: Chat history (list) - required by Gradio ChatInterface\n",
    "    \n",
    "    Returns:\n",
    "        Response string\n",
    "    \"\"\"\n",
    "    # Special handler: show experiments list\n",
    "    if \"show\" in message.lower() and \"experiment\" in message.lower():\n",
    "        exp_names = \"\\n\".join(\n",
    "            [f\"- {exp['experiment_name']}\" for exp in experiments]\n",
    "        )\n",
    "        return f\"\u2705 Available Experiments:\\n{exp_names}\"\n",
    "\n",
    "    # Retrieve dataset context\n",
    "    context = retrieve_context(message)\n",
    "\n",
    "    # Fallback if nothing matches\n",
    "    if context == \"\":\n",
    "        return \"Sorry, I can only answer from the breadboard lessons. Try asking:\\n- 'Show me experiments'\\n- About specific experiments like '2-Pin LED'\\n- About components like 'What is a potentiometer?'\"\n",
    "\n",
    "    # Build grounded prompt\n",
    "    prompt = f\"\"\"\n",
    "{SYSTEM_PROMPT}\n",
    "\n",
    "DATASET CONTEXT:\n",
    "{context}\n",
    "\n",
    "STUDENT QUESTION:\n",
    "{message}\n",
    "\n",
    "Now respond clearly with step-by-step help.\n",
    "\"\"\"\n",
    "\n",
    "    # \u26a0 Use safe wrapper with dataset fallback\n",
    "    fallback = f\"\ud83d\udcda Here's what I found from the experiments:\\n\\n{context}\\n\\nYou can explore this information for your question.\"\n",
    "    \n",
    "    return safe_gemini_generate(prompt, fallback)\n",
    "\n",
    "print(\"\u2705 Chatbot Functions Defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d350168b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "print(\"\ud83d\ude80 Launching Student Chatbot Interface...\")\n",
    "\n",
    "demo = gr.ChatInterface(\n",
    "    fn=breadboard_tutor,\n",
    "    title=\"\ud83e\udd16 Breadboard AI Tutor\",\n",
    "    description=\"Ask about LEDs, buzzers, motors, breadboards, and troubleshooting.\",\n",
    "    examples=[\n",
    "        \"Show me experiments\",\n",
    "        \"Explain 2-Pin LED Breadboard Experiment\",\n",
    "        \"What is an LDR?\",\n",
    "        \"Why is my LED not glowing?\"\n",
    "    ],\n",
    "    type=\"messages\"\n",
    ")\n",
    "\n",
    "demo.launch(share=True, debug=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}